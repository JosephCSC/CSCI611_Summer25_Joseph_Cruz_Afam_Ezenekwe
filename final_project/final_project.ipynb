{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f25c532a",
   "metadata": {},
   "source": [
    "## CSGO ROUND PREDICTING MODEL\n",
    "---\n",
    "In this notebook we are creating a MLP to accurately predict the winner of a CSGO round.\n",
    "Since the data we are dealing with is tabular we chose to use a standard MLP and focus on expanding upon it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040d443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850407b",
   "metadata": {},
   "source": [
    "## Create a Dictionary for easy Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c2489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM = {\n",
    "    'n_epochs': 50,\n",
    "    'learning_rate': 0.0001,\n",
    "    \n",
    "    #normalization function can be min_max, z_score\n",
    "    'norm_func': 'z_score',\n",
    "    #optimizer can be SGD or ADAM\n",
    "    'optim': 'ADAM',\n",
    "    #architecture can be 0, 1 or 2\n",
    "    'model_arch' : 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99016d58",
   "metadata": {},
   "source": [
    "## Load and Normalize the Data\n",
    "---\n",
    "We will load the data from the included csv file \"csgo_round_snapshots.csv\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ef3a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122410 entries, 0 to 122409\n",
      "Columns: 102 entries, time_left to map_de_vertigo\n",
      "dtypes: float64(102)\n",
      "memory usage: 95.3 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.20\n",
    "test_size = .05\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "#load the data into a dataframe using pandas\n",
    "df = pd.read_csv('csgo_round_snapshots.csv')\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(df)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split_1 = int(np.floor(valid_size * num_train))\n",
    "split_2 = int(np.floor(num_train - (test_size * num_train)))\n",
    "train_idx, valid_idx, test_idx = indices[split_1:split_2], indices[:split_1], indices[split_2:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "#now we must seperate the features from the labels\n",
    "features = df.drop('round_winner', axis=1)\n",
    "labels   = df['round_winner']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#perform one hot encoding on the map column\n",
    "features = pd.get_dummies(features,columns=['map'], drop_first=True)\n",
    "\n",
    "for column in features.columns:\n",
    "    #skips if column is a boolean\n",
    "    if pd.api.types.is_bool_dtype(features[column]):\n",
    "        continue\n",
    "\n",
    "    #skips if column does not change in value\n",
    "    if features[column].max() - features[column].min() == 0:\n",
    "        continue\n",
    "    \n",
    "    if PARAM['norm_func'] == 'min_max':\n",
    "        features[column] = (features[column] - features[column].min()) / (features[column].max() - features[column].min())\n",
    "    elif PARAM['norm_func'] == 'z_score':\n",
    "        features[column] = (features[column] - features[column].mean()) / features[column].std()\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "labels = labels.replace({'CT': 0, 'T': 1})\n",
    "\n",
    "#had trouble with boolean type conversion now we implicitly change bools to floats\n",
    "for column in features.select_dtypes(include='bool').columns:\n",
    "    features[column] = features[column].astype(float)\n",
    "\n",
    "features.info()\n",
    "features.describe()\n",
    "\n",
    "\n",
    "features_np = features.values\n",
    "labels_np = labels.values\n",
    "\n",
    "#create tensors from the numpy values\n",
    "features_tensor = torch.tensor(features_np, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels_np, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "#combine the two tensors into the dataset\n",
    "dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "\n",
    "#create the data loaders to be used to train the model\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = DataLoader(dataset,batch_size=batch_size, sampler=test_sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf422c",
   "metadata": {},
   "source": [
    "## Define the Architecture\n",
    "---\n",
    "We are creating 3 seperate models that can be chosen based off of PARAM['model_arch']\n",
    "Each architecture adds more layers and neurons deepening the model as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97066dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Linear(in_features=102, out_features=512, bias=True)\n",
      "  (layer2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (layer3): Linear(in_features=256, out_features=102, bias=True)\n",
      "  (layer4): Linear(in_features=102, out_features=102, bias=True)\n",
      "  (output): Linear(in_features=102, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.35, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "is_Dropout = True\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #defining the layers in the NN  \n",
    "        if PARAM['model_arch'] == 0 :\n",
    "            self.output = nn.Linear(102,1)\n",
    "        elif PARAM['model_arch'] == 1 :\n",
    "\n",
    "            self.layer1 = nn.Linear(102, 256)\n",
    "            self.layer2 = nn.Linear(256,102)\n",
    "            self.output = nn.Linear(102,1)\n",
    "        elif PARAM['model_arch'] == 2 :\n",
    "            self.layer1 = nn.Linear(102, 512)\n",
    "            self.layer2 = nn.Linear(512,256)\n",
    "            self.layer3 = nn.Linear(256,102)\n",
    "            self.layer4 = nn.Linear(102,102)\n",
    "            self.output = nn.Linear(102,1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.35)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        if PARAM['model_arch'] == 0 :\n",
    "            x = F.sigmoid(self.output(x))\n",
    "        elif PARAM['model_arch'] == 1 : \n",
    "            x = F.relu(self.layer1(x))\n",
    "            x = F.relu(self.layer2(x))\n",
    "            if(is_Dropout) : x = self.dropout(x)\n",
    "            x = F.sigmoid(self.output(x))\n",
    "        elif PARAM['model_arch'] == 2 :\n",
    "            x = F.relu(self.layer1(x))\n",
    "            if(is_Dropout) : x = self.dropout(x)\n",
    "            x = F.relu(self.layer2(x))\n",
    "            if(is_Dropout) : x = self.dropout(x)\n",
    "            x = F.relu(self.layer3(x))\n",
    "            x = F.relu(self.layer4(x))\n",
    "            x = F.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "#move tensors to GPU if CUDA is available\n",
    "\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9c096",
   "metadata": {},
   "source": [
    "## Specify Loss Function and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88953254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimizer you selected is: ADAM\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# specify optimizer\n",
    "if PARAM['optim'] == 'SGD':\n",
    "    optimizer = optim.SGD(model.parameters(), PARAM['learning_rate'])\n",
    "    print(\"The optimizer you selected is: SGD\")\n",
    "elif PARAM['optim'] ==  'ADAM':\n",
    "    print(\"The optimizer you selected is: ADAM\")\n",
    "    optimizer = optim.Adam(model.parameters(), PARAM['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ba338",
   "metadata": {},
   "source": [
    "## Training the Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7435aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.488296 \tValidation Loss: 0.453691\n",
      "Validation loss decreased (inf --> 0.453691).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.457946 \tValidation Loss: 0.446433\n",
      "Validation loss decreased (0.453691 --> 0.446433).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.449806 \tValidation Loss: 0.442068\n",
      "Validation loss decreased (0.446433 --> 0.442068).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.445374 \tValidation Loss: 0.439739\n",
      "Validation loss decreased (0.442068 --> 0.439739).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.440355 \tValidation Loss: 0.435952\n",
      "Validation loss decreased (0.439739 --> 0.435952).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.435628 \tValidation Loss: 0.433183\n",
      "Validation loss decreased (0.435952 --> 0.433183).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.432111 \tValidation Loss: 0.431803\n",
      "Validation loss decreased (0.433183 --> 0.431803).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.429723 \tValidation Loss: 0.429350\n",
      "Validation loss decreased (0.431803 --> 0.429350).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.425702 \tValidation Loss: 0.428000\n",
      "Validation loss decreased (0.429350 --> 0.428000).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.423061 \tValidation Loss: 0.426631\n",
      "Validation loss decreased (0.428000 --> 0.426631).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.419153 \tValidation Loss: 0.425032\n",
      "Validation loss decreased (0.426631 --> 0.425032).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.417141 \tValidation Loss: 0.423070\n",
      "Validation loss decreased (0.425032 --> 0.423070).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.413219 \tValidation Loss: 0.420446\n",
      "Validation loss decreased (0.423070 --> 0.420446).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.411480 \tValidation Loss: 0.417552\n",
      "Validation loss decreased (0.420446 --> 0.417552).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.407393 \tValidation Loss: 0.417230\n",
      "Validation loss decreased (0.417552 --> 0.417230).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.404925 \tValidation Loss: 0.412747\n",
      "Validation loss decreased (0.417230 --> 0.412747).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.402112 \tValidation Loss: 0.410133\n",
      "Validation loss decreased (0.412747 --> 0.410133).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.398692 \tValidation Loss: 0.410083\n",
      "Validation loss decreased (0.410133 --> 0.410083).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.395814 \tValidation Loss: 0.407713\n",
      "Validation loss decreased (0.410083 --> 0.407713).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.392877 \tValidation Loss: 0.404386\n",
      "Validation loss decreased (0.407713 --> 0.404386).  Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 0.390366 \tValidation Loss: 0.404832\n",
      "Epoch: 22 \tTraining Loss: 0.387078 \tValidation Loss: 0.401229\n",
      "Validation loss decreased (0.404386 --> 0.401229).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 0.383408 \tValidation Loss: 0.397971\n",
      "Validation loss decreased (0.401229 --> 0.397971).  Saving model ...\n",
      "Epoch: 24 \tTraining Loss: 0.380671 \tValidation Loss: 0.396554\n",
      "Validation loss decreased (0.397971 --> 0.396554).  Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 0.377248 \tValidation Loss: 0.392755\n",
      "Validation loss decreased (0.396554 --> 0.392755).  Saving model ...\n",
      "Epoch: 26 \tTraining Loss: 0.374703 \tValidation Loss: 0.389459\n",
      "Validation loss decreased (0.392755 --> 0.389459).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 0.370171 \tValidation Loss: 0.385389\n",
      "Validation loss decreased (0.389459 --> 0.385389).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.367194 \tValidation Loss: 0.384148\n",
      "Validation loss decreased (0.385389 --> 0.384148).  Saving model ...\n",
      "Epoch: 29 \tTraining Loss: 0.364806 \tValidation Loss: 0.379874\n",
      "Validation loss decreased (0.384148 --> 0.379874).  Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 0.364038 \tValidation Loss: 0.377476\n",
      "Validation loss decreased (0.379874 --> 0.377476).  Saving model ...\n",
      "Epoch: 31 \tTraining Loss: 0.360151 \tValidation Loss: 0.375966\n",
      "Validation loss decreased (0.377476 --> 0.375966).  Saving model ...\n",
      "Epoch: 32 \tTraining Loss: 0.357276 \tValidation Loss: 0.375811\n",
      "Validation loss decreased (0.375966 --> 0.375811).  Saving model ...\n",
      "Epoch: 33 \tTraining Loss: 0.352893 \tValidation Loss: 0.373157\n",
      "Validation loss decreased (0.375811 --> 0.373157).  Saving model ...\n",
      "Epoch: 34 \tTraining Loss: 0.349993 \tValidation Loss: 0.367918\n",
      "Validation loss decreased (0.373157 --> 0.367918).  Saving model ...\n",
      "Epoch: 35 \tTraining Loss: 0.348641 \tValidation Loss: 0.365444\n",
      "Validation loss decreased (0.367918 --> 0.365444).  Saving model ...\n",
      "Epoch: 36 \tTraining Loss: 0.346656 \tValidation Loss: 0.364855\n",
      "Validation loss decreased (0.365444 --> 0.364855).  Saving model ...\n",
      "Epoch: 37 \tTraining Loss: 0.344439 \tValidation Loss: 0.362211\n",
      "Validation loss decreased (0.364855 --> 0.362211).  Saving model ...\n",
      "Epoch: 38 \tTraining Loss: 0.341227 \tValidation Loss: 0.360760\n",
      "Validation loss decreased (0.362211 --> 0.360760).  Saving model ...\n",
      "Epoch: 39 \tTraining Loss: 0.339729 \tValidation Loss: 0.358306\n",
      "Validation loss decreased (0.360760 --> 0.358306).  Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 0.336243 \tValidation Loss: 0.357012\n",
      "Validation loss decreased (0.358306 --> 0.357012).  Saving model ...\n",
      "Epoch: 41 \tTraining Loss: 0.334362 \tValidation Loss: 0.355160\n",
      "Validation loss decreased (0.357012 --> 0.355160).  Saving model ...\n",
      "Epoch: 42 \tTraining Loss: 0.331458 \tValidation Loss: 0.352653\n",
      "Validation loss decreased (0.355160 --> 0.352653).  Saving model ...\n",
      "Epoch: 43 \tTraining Loss: 0.329170 \tValidation Loss: 0.351007\n",
      "Validation loss decreased (0.352653 --> 0.351007).  Saving model ...\n",
      "Epoch: 44 \tTraining Loss: 0.326349 \tValidation Loss: 0.348062\n",
      "Validation loss decreased (0.351007 --> 0.348062).  Saving model ...\n",
      "Epoch: 45 \tTraining Loss: 0.323990 \tValidation Loss: 0.347040\n",
      "Validation loss decreased (0.348062 --> 0.347040).  Saving model ...\n",
      "Epoch: 46 \tTraining Loss: 0.321007 \tValidation Loss: 0.344033\n",
      "Validation loss decreased (0.347040 --> 0.344033).  Saving model ...\n",
      "Epoch: 47 \tTraining Loss: 0.320935 \tValidation Loss: 0.341661\n",
      "Validation loss decreased (0.344033 --> 0.341661).  Saving model ...\n",
      "Epoch: 48 \tTraining Loss: 0.315664 \tValidation Loss: 0.339609\n",
      "Validation loss decreased (0.341661 --> 0.339609).  Saving model ...\n",
      "Epoch: 49 \tTraining Loss: 0.314589 \tValidation Loss: 0.340997\n",
      "Epoch: 50 \tTraining Loss: 0.313809 \tValidation Loss: 0.337188\n",
      "Validation loss decreased (0.339609 --> 0.337188).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\AppData\\Local\\Temp\\ipykernel_7032\\1428333273.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model_trained.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "training_loss_list = []\n",
    "validation_loss_list = []\n",
    "\n",
    "overfit_Counter = 0\n",
    "\n",
    "for epoch in range(1, PARAM['n_epochs'] + 1):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "\n",
    "    training_loss_list.append(train_loss)\n",
    "    validation_loss_list.append(valid_loss)\n",
    "\n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_trained.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "        overfit_Counter = 0\n",
    "    else:\n",
    "        overfit_Counter+=1\n",
    "        if(overfit_Counter >= 3):\n",
    "            break\n",
    "\n",
    "\n",
    "#Plot the data to see the Training validation loss curve\n",
    "\n",
    "plt.plot(range(1, len(training_loss_list) + 1), training_loss_list, label='Training Loss',)\n",
    "plt.plot(range(1, len(validation_loss_list) + 1), validation_loss_list, label='Validation Loss',)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.ylim(0.0, 1.0) \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('model_trained.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9def4ec",
   "metadata": {},
   "source": [
    "## Test the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f493a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.016849\n",
      "\n",
      "Test Accuracy of    CT: 83% (2535/3027)\n",
      "Test Accuracy of     T: 85% (2636/3094)\n",
      "\n",
      "Test Accuracy (Overall): 84% (5171/6121)\n"
     ]
    }
   ],
   "source": [
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "classes = ['CT', 'T']\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    pred = (output >= .5).float()\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "\n",
    "    batch_size = data.size(0)\n",
    "    for i in range(batch_size):\n",
    "        label = int(target[i].item())\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "         print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "             classes[i], 100 * class_correct[i] / class_total[i],\n",
    "             int(class_correct[i]), int(class_total[i]))) # Cast sums to int for printing\n",
    "    else:\n",
    "         print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    int(np.sum(class_correct)), int(np.sum(class_total)))) # Cast sums to int for printing\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
